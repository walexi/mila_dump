{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "af8sV4iibInQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "walexi",
      "language": "python",
      "name": "walexi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walexi/mila_dump/blob/master/Copy_of_BiasCorp_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApaCBYSzRszF"
      },
      "source": [
        "!pip install -U pytorch-lightning comet-ml transformers optuna wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXTnDZF-Hyqm"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score, r2_score, average_precision_score, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import optuna\n",
        "from ast import literal_eval\n",
        "import copy\n",
        "# from datasets import  load_metric\n",
        "from transformers import BertModel, BertTokenizerFast, BertLayer\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from hopfield import HopfieldLayer, Hopfield, HopfieldPooling, HopfieldCore\n",
        "# %matplotlib inline\n",
        "# plt.set_cmap('jet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq-WjC7jQ4tM"
      },
      "source": [
        "DATA_ROOT = 'bias_corp.csv'\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 3\n",
        "MAX_LEN = 512\n",
        "TRIALS = 3\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "TOKENIZER = BertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "BASE_MODEL = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "DATA = pd.read_csv(DATA_ROOT)\n",
        "df = DATA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4gLK4ySLmr"
      },
      "source": [
        "df['confidence_sum'] = df.apply(lambda row: sum([row['confidence_1'], row['confidence_2'], row['confidence_3']]), axis=1)\n",
        "df['class_indices'] = df.apply(lambda row: np.asarray([row['bias_1'], row['bias_2'], row['bias_3']]), axis=1)\n",
        "df['conf_scores'] = df.apply(lambda row: np.asarray([row['confidence_1'], row['confidence_2'], row['confidence_3']])/row['confidence_sum'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl4sPhqZTVdD"
      },
      "source": [
        "import re\n",
        "\n",
        "regex = re.compile(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)|(\\\\n)|(\\\\r)|(\\\\t)|(\\<+?.+?\\>)\", re.IGNORECASE)\n",
        "regex2 = re.compile(\"(\\\\')\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0NS2P05TXpO"
      },
      "source": [
        "df.loc[:, 'text'] = df.text.apply(lambda ele: regex.sub(\"\",ele))\n",
        "df.loc[:, 'text'] = df.text.apply(lambda ele: regex2.sub(\"'\",ele))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNBZqYhyTlv-"
      },
      "source": [
        "DATA = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIZOqYPGLkpO"
      },
      "source": [
        "@dataclass\n",
        "class Data:\n",
        "    train: pd.DataFrame\n",
        "    val: pd.DataFrame\n",
        "    test: pd.DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aZY-rWIptu3"
      },
      "source": [
        "def shuffle_dist(dataframe: pd.DataFrame, split_ratio: float=0.6) -> (Data, str):\n",
        "    \"\"\"randomly split dataset into train and val set based on the source column\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataframe : pd.Dataframe\n",
        "    dataset in pandas dataframe type\n",
        "    split_ratio : float\n",
        "    for a given source, percent of entries to split\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Data\n",
        "    dataclass with fields train, val, and test\n",
        "\n",
        "    \"\"\"\n",
        "    coin = random.choice([0,1])\n",
        "    type_ = \"\"\n",
        "    if coin:\n",
        "        type_ = 'Fox'\n",
        "        ratio = int(len(dataframe[dataframe['source']==type_]) * split_ratio)\n",
        "        train = pd.concat([ dataframe[dataframe['source']=='BB'], dataframe[dataframe['source']==type_][:ratio] ])\n",
        "        val = dataframe[dataframe['source']==type_][ratio:]\n",
        "        test = dataframe[dataframe['source']=='Youtube']\n",
        "    else:\n",
        "        type_ = 'BB'\n",
        "        ratio = int(len(dataframe[dataframe['source']==type_]) * split_ratio)\n",
        "        train = pd.concat([ dataframe[dataframe['source']=='Fox'], dataframe[dataframe['source']==type_][:ratio] ])\n",
        "        val = dataframe[dataframe['source']==type_][ratio:]\n",
        "        test = dataframe[dataframe['source']=='Youtube']\n",
        "\n",
        "    return Data(train,val,test), type_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo_24Ip4fMPz"
      },
      "source": [
        "def one_hot(conf_scores, cls_indices):\n",
        "  empty = torch.zeros((1,6), dtype=torch.float)\n",
        "  cls = torch.tensor([cls_indices], dtype=torch.long)\n",
        "  conf = torch.tensor([conf_scores], dtype=torch.float)\n",
        "\n",
        "  return empty.scatter_(1, cls, conf, reduce='add')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0zYwCdBoCRh"
      },
      "source": [
        "class BiasDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.config = {\n",
        "            'max_len': max_len,\n",
        "            'return_attention_mask': True,\n",
        "            'padding': 'max_length',\n",
        "            'truncation': True,\n",
        "            'return_tensors': 'pt',\n",
        "            'return_token_type_ids': False\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        entry = self.df.iloc[item]\n",
        "        text = entry.text\n",
        "        config = {\n",
        "            'max_length': self.max_len,\n",
        "            'return_attention_mask': True,\n",
        "            'padding': 'max_length',\n",
        "            'truncation': True,\n",
        "            'return_tensors': 'pt',\n",
        "            'return_token_type_ids': False\n",
        "        }\n",
        "        encoding = self.tokenizer(text, **config)\n",
        "\n",
        "        try:\n",
        "            conf_scores = entry.conf_scores\n",
        "            indices = entry.class_indices\n",
        "            target = one_hot(conf_scores, indices)\n",
        "\n",
        "            return {\n",
        "              'text': text,\n",
        "              'input_ids': encoding['input_ids'],\n",
        "              'attention_mask' : encoding['attention_mask'],\n",
        "              'target': target\n",
        "            }\n",
        "\n",
        "        except KeyError:\n",
        "\n",
        "            return {\n",
        "              'text': text,\n",
        "              'input_ids': encoding['input_ids'],\n",
        "              'attention_mask': encoding['attention_mask']\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wicsMi-TpqLU"
      },
      "source": [
        "class BackBone(nn.Module):\n",
        "\n",
        "    def __init__(self, base, trials=None, isFrozen=True, useHopfieldPool=False):\n",
        "        super(BackBone, self).__init__()\n",
        "\n",
        "        self.bert = base\n",
        "\n",
        "        self.useHopfieldPool = useHopfieldPool\n",
        "\n",
        "        if isFrozen:\n",
        "            for layer in self.bert.parameters():\n",
        "                layer.requires_grad = False\n",
        "\n",
        "\n",
        "            # hopfield = EncoderLayer(bert.config,0.2)\n",
        "\n",
        "            # self.bert = replaceLayer(bert, hopfield, [7,8,9])\n",
        "            # # self.bi_lstm = return sequences and apply dropout\n",
        "            # # max_pool\n",
        "            # # dense then dropout and dense_output\n",
        "        if useHopfieldPool:\n",
        "          output_size = self.bert.config.hidden_size\n",
        "          self.hopfield_pool = HopfieldPooling(self.bert.config.hidden_size, hidden_size=32, output_size=output_size, num_heads=1)\n",
        "        else:\n",
        "          output_size = 512\n",
        "          self.lin0 = nn.Linear(self.bert.config.hidden_size, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(trials.suggest_uniform('dropout_rate', 0.2, 0.5))\n",
        "\n",
        "        self.lin1 = nn.Linear(output_size, 6)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask = None):\n",
        "\n",
        "        output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_attentions=False\n",
        "            )\n",
        "\n",
        "        out = output.pooler_output\n",
        "\n",
        "        if self.useHopfieldPool:\n",
        "          out = out.unsqueeze(1)\n",
        "          out = self.hopfield_pool(out)\n",
        "        else:\n",
        "          out = self.lin0(out)\n",
        "\n",
        "        out = self.lin1(self.dropout(out))\n",
        "\n",
        "        return out, output.attentions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKm8GxRLb5r3"
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, tokenizer, dataframe, criterion, batch_size, trial=None):\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.model  = model.to(self.device)\n",
        "\n",
        "        self.trial = trial\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.bce_loss = criterion\n",
        "\n",
        "        self.label_binarizer = MultiLabelBinarizer(classes=[0,1,2,3,4,5])\n",
        "\n",
        "        self._init(dataframe, tokenizer)\n",
        "\n",
        "\n",
        "    def _init(self, df, tokenizer):\n",
        "\n",
        "        dataset, self.s_type = shuffle_dist(df) #report what source is used for val and log with trial number\n",
        "\n",
        "        train_ds = BiasDataset(dataset.train, max_len=MAX_LEN, tokenizer=tokenizer)\n",
        "        val_ds = BiasDataset(dataset.val, max_len=MAX_LEN, tokenizer=tokenizer)\n",
        "        test_ds  = BiasDataset(dataset.test, max_len=MAX_LEN, tokenizer=tokenizer)\n",
        "\n",
        "        self.train_dl = DataLoader(train_ds, num_workers=NUM_WORKERS, batch_size= self.batch_size, shuffle=True)\n",
        "        self.test_dl = DataLoader(test_ds, num_workers=NUM_WORKERS, batch_size= self.batch_size, shuffle=True)\n",
        "        self.val_dl = DataLoader(val_ds, num_workers=NUM_WORKERS, batch_size= self.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    def compute_metrics(self, logits, targets, end_of_epoch=False, isTrain=True):\n",
        "\n",
        "        if end_of_epoch and not isTrain:\n",
        "            # transform to label indicators for each topk\n",
        "            pred_matrix = [self.label_binarizer.fit_transform(logits[i]) for i in range(3)]\n",
        "            targ_matrix = [self.label_binarizer.fit_transform(targets[i]) for i in range(3)]\n",
        "\n",
        "            # ap for each class in an array of class length\n",
        "            average_precision = [ average_precision_score(targ_matrix[i], pred_matrix[i], average=None) for i in range(3) ]\n",
        "            # print(pred_matrix[0].shape) (8392, 2)\n",
        "            # mean average precision\n",
        "            map_ = [average_precision_score(targ_matrix[i], pred_matrix[i], average='macro') for i in range(3)]\n",
        "\n",
        "            # array of tuple(precision recall f1_score) for each class\n",
        "            prec_recall_f1 = [ [ (precision_recall_fscore_support(targ_matrix[j][:,i], pred_matrix[j][:,i], average='micro'))[0:3] for i in range(6)] for j in range(3)]\n",
        "\n",
        "            return average_precision, map_, prec_recall_f1\n",
        "\n",
        "        loss = self.bce_loss(logits, targets)\n",
        "\n",
        "        if not isTrain:\n",
        "\n",
        "            prob = F.softmax(logits, dim=1)\n",
        "            prob = prob.cpu()\n",
        "            # r2_score = r2_score(targets.numpy(), prob, multioutput='raw_values')\n",
        "            topk_preds = [0]*3\n",
        "            topk_targs = [0]*3\n",
        "\n",
        "            for i in range(3):\n",
        "                topk_pred = prob.topk(i+1).indices.numpy()\n",
        "                topk_targ = targets.cpu().topk(i+1).indices.numpy()\n",
        "                topk_preds[i]=topk_pred\n",
        "                topk_targs[i]=topk_targ\n",
        "\n",
        "            return loss, topk_preds, topk_targs\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def fit(self, epochs, lr):\n",
        "\n",
        "        config = wandb.config\n",
        "        config.batch_size = self.batch_size\n",
        "        config.epochs = epochs\n",
        "        config.lr = lr\n",
        "        config.no_cuda = False\n",
        "        config.log_interval = 10\n",
        "\n",
        "        optimizer = AdamW(self.model.parameters(), lr=config.lr, correct_bias=False)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(self.train_dl)* epochs)\n",
        "\n",
        "        for epoch in tqdm(range(config.epochs)):\n",
        "\n",
        "            train_loss  = self.train(optimizer, scheduler)\n",
        "\n",
        "            val_loss, avg_prec, map_, prec_rec_f1 = self.val()\n",
        "              # self.test() # may run after x epochs given the best model so far\n",
        "\n",
        "            wandb.log({'train_loss_epoch': np.mean(train_loss), 'epoch': epoch, trial: self.trial.number },commit=False)\n",
        "\n",
        "            wandb.log( {'val_loss_epoch': np.mean(val_loss), 'average_precision': avg_prec,'mean_avg_precision': map_, 'precision_recall_f1': prec_rec_f1, 'epoch': epoch, trial: self.trial.number, 'source_val': self.s_type })\n",
        "\n",
        "        sample = next(iter(self.train_dl))\n",
        "        flops_count, params_count = get_model_complexity_info(self.model,\n",
        "                                         tuple(sample['input_ids'].squeeze(1).size()),\n",
        "                                         input_constructor=lambda x: { 'input_ids': sample['input_ids'].squeeze(1) },\n",
        "                                         print_per_layer_stat=False, as_strings=False, verbose=False)\n",
        "\n",
        "        return val_loss, map_, flops_count\n",
        "\n",
        "    def train(self, optimizer, scheduler):\n",
        "        self.model.train()\n",
        "\n",
        "        total_loss = []\n",
        "        steps = 0\n",
        "        for batch_idx, entry in enumerate(self.train_dl):\n",
        "\n",
        "            input_ids = entry['input_ids'].to(self.device)\n",
        "            attention_mask = entry['attention_mask'].to(self.device)\n",
        "            targets = entry['target'].to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = self.model(input_ids.squeeze(1), attention_mask.squeeze(1))\n",
        "\n",
        "            loss = self.compute_metrics(logits, targets.squeeze(1))\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "            steps += 1\n",
        "\n",
        "            if ((steps+1)%25==0):\n",
        "                wandb.log({'train_loss_batch': loss.item(), 'steps': steps, 'trial_number': self.trial.number })\n",
        "\n",
        "            total_loss.append(loss.item())\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "    def val(self):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = []\n",
        "        topk_predictions = None\n",
        "        topk_targets = None\n",
        "\n",
        "        steps = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for entry in self.val_dl:\n",
        "\n",
        "                steps += 1\n",
        "\n",
        "                input_ids = entry['input_ids'].to(self.device)\n",
        "                attention_mask = entry['attention_mask'].to(self.device)\n",
        "                targets = entry['target'].to(self.device)\n",
        "\n",
        "                logits, _ = self.model(input_ids.squeeze(1), attention_mask.squeeze(1))\n",
        "                # k:int -> arr\n",
        "\n",
        "                loss, topk_preds, topk_targs = self.compute_metrics(logits, targets.squeeze(1), isTrain=False)\n",
        "\n",
        "                if ((steps+1)%25==0):\n",
        "                    wandb.log({'val_loss_batch': loss.item(), 'steps': steps, 'trial_number': self.trial.number })\n",
        "\n",
        "                if topk_predictions is None:\n",
        "                    topk_predictions = topk_preds\n",
        "                else:\n",
        "                    topk_predictions = [np.concatenate((prev, curr), axis=0) for prev, curr in zip(topk_predictions,topk_preds)]\n",
        "\n",
        "                if topk_targets is None:\n",
        "                    topk_targets = topk_targs\n",
        "                else:\n",
        "                    topk_targets = [np.concatenate((prev, curr), axis=0) for prev, curr in zip(topk_targets,topk_targs)]\n",
        "\n",
        "                total_loss.append(loss.item())\n",
        "\n",
        "            avg_prec, map_, prec_rec_f1 = self.compute_metrics(topk_predictions, topk_targets, end_of_epoch=True, isTrain=False)\n",
        "\n",
        "        return total_loss, avg_prec, map_, prec_rec_f1\n",
        "\n",
        "    def test(self):\n",
        "        # self.model.eval()\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L5BMDI_qF34"
      },
      "source": [
        "def objective(trial):\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model = BackBone(BASE_MODEL, trial)\n",
        "\n",
        "    wandb.watch(model, criterion, log='all')\n",
        "\n",
        "    trainer = Trainer(model, TOKENIZER, DATA, criterion, BATCH_SIZE, trial)\n",
        "\n",
        "    lr = trial.suggest_loguniform('learning_rate', 2e-5, 5e-5)\n",
        "\n",
        "    EPOCHS = 1\n",
        "\n",
        "    val_loss, map_, flops_count = trainer.fit(EPOCHS, lr)\n",
        "\n",
        "\n",
        "    return val_loss, map_, flops_count\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIWDLIZQ4tg"
      },
      "source": [
        "def main():\n",
        "\n",
        "\n",
        "#     wandb.login(key=\"\")\n",
        "    wandb.init(project=\"final-paper\", id='my', save_code=True, name='temp', reinit=True, entity=\"walexi4great\")\n",
        "#     %env WANDB_LOG_MODEL=true\n",
        "#     %env WANDB_WATCH='all'\n",
        "\n",
        "#     DATA_ROOT = '/home/walexi/scratch/bias/final/dataset/data.csv'\n",
        "#     BATCH_SIZE = 8\n",
        "#     NUM_WORKERS = 3\n",
        "#     MAX_LEN = 512\n",
        "#     TRIALS = 3\n",
        "#     PRE_TRAINED_MODEL_NAME = '/home/walexi/scratch/bias/final/bert_base_cased'\n",
        "#     TOKENIZER = BertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "#     BASE_MODEL = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "#     DATA = pd.read_csv(DATA_ROOT)\n",
        "\n",
        "    study = optuna.create_study(study_name='Final Paper', directions=['minimize', 'maximize', 'minimize'])\n",
        "\n",
        "    study.optimize(objective, n_trials=TRIALS)\n",
        "\n",
        "    return study\n",
        "\n",
        "#     print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "#     print(\"Best trial:\")\n",
        "#     trial = study.best_trial\n",
        "\n",
        "#     print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "#     print(\"  Params: \")\n",
        "#     for key, value in trial.params.items():\n",
        "#         print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "#     # Visualize the optimization history.\n",
        "#     plot_optimization_history(study).show()\n",
        "\n",
        "#     # Visualize the learning curves of the trials.\n",
        "#     plot_intermediate_values(study).show()\n",
        "\n",
        "#     # Visualize high-dimensional parameter relationships.\n",
        "#     plot_parallel_coordinate(study).show()\n",
        "\n",
        "#     # Select parameters to visualize.\n",
        "#     plot_parallel_coordinate(study, params=[\"lr_init\", \"n_units_l0\"]).show()\n",
        "\n",
        "#     # Visualize hyperparameter relationships.\n",
        "#     plot_contour(study).show()\n",
        "\n",
        "#     # Select parameters to visualize.\n",
        "#     plot_contour(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
        "\n",
        "#     # Visualize individual hyperparameters.\n",
        "#     plot_slice(study).show()\n",
        "\n",
        "#     # Select parameters to visualize.\n",
        "#     plot_slice(study, params=[\"n_units_l0\", \"n_units_l1\"]).show()\n",
        "\n",
        "#     # Visualize parameter importances.\n",
        "#     plot_param_importances(study).show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "-JBO9sR3Q4tg",
        "outputId": "48dcf48d-3f8a-4bff-ba28-b1f9f4c51103"
      },
      "source": [
        "res = main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.20<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">temp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/walexi4great/final-paper\" target=\"_blank\">https://wandb.ai/walexi4great/final-paper</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/walexi4great/final-paper/runs/my\" target=\"_blank\">https://wandb.ai/walexi4great/final-paper/runs/my</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210224_140119-my</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-24 14:01:23,964]\u001b[0m A new study created in memory with name: Final Paper\u001b[0m\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyc8sYsPQ4th"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}